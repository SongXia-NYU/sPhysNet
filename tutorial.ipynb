{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction to Explore Chemical Space with 3D Geometry and Deep Learning\n",
    "\n",
    "This is a tutorial on how to train a simplified PhysNet (sPhysNet) on Frag20 dataset described in this [paper]($PLACEHOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the code and data\n",
    "\n",
    "First you should download the code for data preprocessing (/dataProviders) and model training(/PhysDime-Seq). You can do it by:\n",
    "\n",
    "\n",
    "` $ git clone --recurse-submodules -j8 https://github.com/SongXia-NYU/sPhysNet.git`\n",
    "\n",
    "You need to setup the environment variable:\n",
    "\n",
    "` $ export PYTHONPATH=./dataProviders/:$PYTHONPATH `\n",
    "\n",
    "` $ export PYTHONPATH=./PhysDime-Seq/:$PYTHONPATH `\n",
    "\n",
    "before you launch this notebook: \n",
    "\n",
    "` $ jupyter notebook `\n",
    "\n",
    "This tutorial file is supposed to be in the /sPhysNet folder, which is the same level as /dataProviders and /PhysDime-Seq\n",
    "\n",
    "Download Frag20 data from our website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: missing URL\r\n",
      "Usage: wget [OPTION]... [URL]...\r\n",
      "\r\n",
      "Try `wget --help' for more options.\r\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "! wget ${website}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to extract the *.tar.bz2 file to wherever is convinent for you. You may need to change the line below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change me\n",
    "frag20_data_root = \"/ext3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "\n",
    "def check_frag20_data(root):\n",
    "    for n_heavy in tqdm(range(9, 21)):\n",
    "        csv_file = osp.join(root, \"Frag20_{}_target.csv\".format(n_heavy))\n",
    "        pt_file = osp.join(root, \"Frag20_{}_extra_target.pt\".format(n_heavy))\n",
    "        sdf_folder = osp.join(root, \"Frag20_{}_data\".format(n_heavy))\n",
    "        for f in [csv_file, pt_file, sdf_folder]:\n",
    "            if not osp.exists(f):\n",
    "                raise ValueError(\"file/folder: {} doesn't exist! Is your root correct?\".format(f))\n",
    "    print(\"Frag20 data status: Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frag20 data status: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_frag20_data(frag20_data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the downloaded data, all geometries and targets are in different format. There we need to preprocess them into a single `torch_geometric.data.InMemoryDataset` format. I have written a function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from dataProviders.GaussUtils.GaussInfo import sdf_to_pt\n",
    "dst_dir = \"dataProviders/data/processed\"\n",
    "os.makedirs(dst_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing extract geometry, targets and calculate `edge_index` as well. The whole process took several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing heavy: 9: 100%|██████████| 158535/158535 [22:09<00:00, 119.24it/s]\n",
      "processing heavy: 10: 100%|██████████| 143180/143180 [29:36<00:00, 80.61it/s] \n",
      "processing heavy: 11: 100%|██████████| 17269/17269 [03:28<00:00, 82.85it/s] \n",
      "processing heavy: 12: 100%|██████████| 21502/21502 [05:00<00:00, 71.51it/s] \n",
      "processing heavy: 13: 100%|██████████| 25793/25793 [06:51<00:00, 62.61it/s] \n",
      "processing heavy: 14: 100%|██████████| 30331/30331 [09:01<00:00, 56.03it/s] \n",
      "processing heavy: 15: 100%|██████████| 31719/31719 [10:20<00:00, 51.13it/s]\n",
      "processing heavy: 16: 100%|██████████| 35584/35584 [12:41<00:00, 46.72it/s]\n",
      "processing heavy: 17: 100%|██████████| 36201/36201 [14:15<00:00, 42.31it/s]\n",
      "processing heavy: 18: 100%|██████████| 32501/32501 [14:04<00:00, 38.49it/s]\n",
      "processing heavy: 19: 100%|██████████| 23474/23474 [11:19<00:00, 34.55it/s]\n",
      "processing heavy: 20: 100%|██████████| 10207/10207 [05:48<00:00, 29.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# ------------- Frag20 Data preprocess------------- #\n",
    "\n",
    "for n_heavy in range(9, 21):\n",
    "    sdf_to_pt(n_heavy=n_heavy, src_root=frag20_data_root, dst_root=dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frag20_eMol9_QM.pt\r\n",
      "eMol9_raw.pt\r\n",
      "frag20_10_raw.pt\r\n",
      "frag20_11_raw.pt\r\n",
      "frag20_12_raw.pt\r\n",
      "frag20_13_raw.pt\r\n",
      "frag20_14_raw.pt\r\n",
      "frag20_15_raw.pt\r\n",
      "frag20_16_raw.pt\r\n",
      "frag20_17_raw.pt\r\n",
      "frag20_18_raw.pt\r\n",
      "frag20_19_raw.pt\r\n",
      "frag20_20_raw.pt\r\n",
      "frag20_9_raw.pt\r\n",
      "frag20_eMol9_split.pt\r\n",
      "frag20reducedAllSolRef-Bmsg-cutoff-10.00-sorted-defined_edge-lr-QM.pt\r\n"
     ]
    }
   ],
   "source": [
    "! ls dataProviders/data/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R',\n",
       " 'Z',\n",
       " 'Q',\n",
       " 'D',\n",
       " 'F',\n",
       " 'E',\n",
       " 'N',\n",
       " 'BN_edge_index',\n",
       " 'L_edge_index',\n",
       " 'num_L_edge',\n",
       " 'num_BN_edge']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "frag20_20_raw = torch.load(\"dataProviders/raw/frag20_20_raw.pt\")\n",
    "frag20_20_raw[0].keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also you need to do the same procedure to preprocess eMol9 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ eMol9 data preprocess ---------------- #\n",
    "\n",
    "# change me\n",
    "eMol9_data_root = \"/scratch/sx801/data/eMol9/eMol9_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataProviders.GaussUtils.GaussInfo import sdf_to_pt_eMol9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88234/88234 [15:54<00:00, 92.45it/s] \n"
     ]
    }
   ],
   "source": [
    "sdf_to_pt_eMol9(src_root=eMol9_data_root, dst_root=dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataProviders/data/processed/eMol9_raw.pt\r\n"
     ]
    }
   ],
   "source": [
    "! ls dataProviders/data/processed/eMol9*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "frag20_9_raw.pt: 100%|██████████| 158535/158535 [00:25<00:00, 6105.57it/s]\n",
      "frag20_10_raw.pt: 100%|██████████| 143180/143180 [00:23<00:00, 6061.26it/s]\n",
      "frag20_11_raw.pt: 100%|██████████| 17269/17269 [00:02<00:00, 7031.08it/s]\n",
      "frag20_12_raw.pt: 100%|██████████| 21502/21502 [00:03<00:00, 7070.70it/s]\n",
      "frag20_13_raw.pt: 100%|██████████| 25793/25793 [00:03<00:00, 7028.68it/s]\n",
      "frag20_14_raw.pt: 100%|██████████| 30331/30331 [00:06<00:00, 5044.81it/s]\n",
      "frag20_15_raw.pt: 100%|██████████| 31719/31719 [00:04<00:00, 6991.87it/s]\n",
      "frag20_16_raw.pt: 100%|██████████| 35584/35584 [00:07<00:00, 5025.57it/s]\n",
      "frag20_17_raw.pt: 100%|██████████| 36201/36201 [00:05<00:00, 7054.65it/s]\n",
      "frag20_18_raw.pt: 100%|██████████| 32501/32501 [00:04<00:00, 7038.79it/s]\n",
      "frag20_19_raw.pt: 100%|██████████| 23474/23474 [00:03<00:00, 7073.40it/s]\n",
      "frag20_20_raw.pt: 100%|██████████| 10207/10207 [00:01<00:00, 7070.00it/s]\n",
      "eMol9_raw.pt: 100%|██████████| 88234/88234 [00:15<00:00, 5865.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving... it is recommended to have 32GB memory\n"
     ]
    }
   ],
   "source": [
    "# ----------- Concat datasets ----------------- #\n",
    "\n",
    "# recommened memory: 32GB\n",
    "from DataPrepareUtils import concat_im_datasets\n",
    "data_root = \"./dataProviders/data\"\n",
    "datasets = [\"frag20_{}_raw.pt\".format(i) for i in range(9, 21)]\n",
    "datasets.append(\"eMol9_raw.pt\")\n",
    "concat_im_datasets(root=data_root, datasets=datasets, out_name=\"Frag20_eMol9_QM.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now we have prepared frag20 and eMol9 dataset with QM geometry. We are ready to train a QM optimized model. First we need to join the training folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sx801/scripts/sPhysNet\n",
      "/scratch/sx801/scripts/sPhysNet/PhysDime-Seq\n",
      "/scratch/sx801/scripts/sPhysNet/PhysDime-Seq\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "%cd PhysDime-Seq\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DummyIMDataset import DummyIMDataset\n",
    "frag20_eMol9_QM_dataset = DummyIMDataset(root=\"../dataProviders/data\", dataset_name=\"Frag20_eMol9_QM.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654530"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frag20_eMol9_QM_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the same result as the paper, we will load the same train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = torch.load(\"../dataProviders/frag20_eMol9_split.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([583261,  19821, 213143,  ...,  90419, 482983, 121258])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train-valid split is randomly generated on the fly\n",
    "train_perm = torch.randperm(len(split[\"train_index\"]))\n",
    "train_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag20_eMol9_QM_dataset.train_index = split[\"train_index\"][train_perm[:-1000]]\n",
    "frag20_eMol9_QM_dataset.val_index = split[\"train_index\"][train_perm[-1000:]]\n",
    "frag20_eMol9_QM_dataset.test_index = split[\"test_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--debug_mode=False\r\n",
      "--modules=P-noOut P-noOut P C\r\n",
      "--bonding_type=BN BN BN BN\r\n",
      "--activations=ssp ssp ssp\r\n",
      "--expansion_fn=(P_BN,P-noOut_BN):gaussian_64_10.0 C_BN:coulomb_10.0\r\n",
      "--n_feature=160\r\n",
      "--n_dime_before_residual=1\r\n",
      "--n_dime_after_residual=2\r\n",
      "--n_output_dense=3\r\n",
      "--n_phys_atomic_res=1\r\n",
      "--n_phys_interaction_res=1\r\n",
      "--n_phys_output_res=1\r\n",
      "--n_bi_linear=8\r\n",
      "--num_epochs=1000\r\n",
      "--warm_up_steps=0\r\n",
      "--data_provider=frag20_eMol9_combine\r\n",
      "--test_interval=-1\r\n",
      "--learning_rate=0.001\r\n",
      "--ema_decay=0.999\r\n",
      "--l2lambda=0.0\r\n",
      "--nh_lambda=0.01\r\n",
      "--restrain_non_bond_pred=True\r\n",
      "--decay_steps=620000\r\n",
      "--decay_rate=0.1\r\n",
      "--batch_size=100\r\n",
      "--valid_batch_size=32\r\n",
      "--force_weight=0\r\n",
      "--charge_weight=1\r\n",
      "--dipole_weight=1\r\n",
      "--use_trained_model=False\r\n",
      "--max_norm=1000.0\r\n",
      "--log_file_name=training.log\r\n",
      "--normalize=True\r\n",
      "--shared_normalize_param=True\r\n",
      "--edge_version=cutoff\r\n",
      "--cutoff=10.0\r\n",
      "--boundary_factor=100.\r\n",
      "--remove_atom_ids=-1\r\n",
      "--folder_prefix=exp-sPhysNet-QM\r\n",
      "--comment=original PhysNet, coulomb correction\r\n",
      "--coulomb_charge_correct=True\r\n"
     ]
    }
   ],
   "source": [
    "# Use this config file to train a sPhysNet in the paper\n",
    "! cat config-sPhysNet-Frag20-eMol9-QM.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_functions import add_parser_arguments\n",
    "config_name = \"config-sPhysNet-Frag20-eMol9-QM.txt\"\n",
    "# set up parser and arguments\n",
    "parser = argparse.ArgumentParser(fromfile_prefix_chars='@')\n",
    "parser = add_parser_arguments(parser)\n",
    "\n",
    "args, unknown = parser.parse_known_args([\"@\" + config_name])\n",
    "args.config_name = config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(BN_edge_index=[2, 272], D=[1, 3], E=[1], F=[1, 3], L_edge_index=[2, 0], N=[1], Q=[1], R=[17, 3], Z=[17], num_BN_edge=[1], num_L_edge=[1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag20_eMol9_QM_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7892096)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag20_eMol9_QM_dataset.data.num_L_edge.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING ATOM -1 FROM DATASET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0: 5969it [15:36,  6.37it/s]\n",
      "epoch: 1: 5969it [14:12,  7.00it/s]\n",
      "epoch: 2: 5969it [14:13,  7.00it/s]\n",
      "epoch: 3: 5969it [14:12,  7.00it/s]\n",
      "epoch: 4: 5969it [14:13,  6.99it/s]\n",
      "epoch: 5: 5969it [14:04,  7.07it/s]\n",
      "epoch: 6: 5969it [14:10,  7.02it/s]\n",
      "epoch: 7: 5969it [14:10,  7.01it/s]\n",
      "epoch: 8: 5969it [14:11,  7.01it/s]\n",
      "epoch: 9: 5969it [14:12,  7.00it/s]\n",
      "epoch: 10: 5969it [14:10,  7.02it/s]\n",
      "epoch: 11: 5969it [14:12,  7.00it/s]\n",
      "epoch: 12: 5969it [14:11,  7.01it/s]\n",
      "epoch: 13: 5969it [14:11,  7.01it/s]\n",
      "epoch: 14: 5969it [14:11,  7.01it/s]\n",
      "epoch: 15: 5969it [14:11,  7.01it/s]\n",
      "epoch: 16: 5969it [14:14,  6.99it/s]\n",
      "epoch: 17: 5969it [14:12,  7.00it/s]\n",
      "epoch: 18: 5969it [14:12,  7.00it/s]\n",
      "epoch: 19: 5969it [14:12,  7.00it/s]\n",
      "epoch: 20: 5969it [14:13,  6.99it/s]\n",
      "epoch: 21: 5969it [14:11,  7.01it/s]\n",
      "epoch: 22: 5969it [14:13,  7.00it/s]\n",
      "epoch: 23: 5969it [14:11,  7.01it/s]\n",
      "epoch: 24: 5969it [14:12,  7.01it/s]\n",
      "epoch: 25: 5969it [14:11,  7.01it/s]\n",
      "epoch: 26: 5969it [14:12,  7.00it/s]\n",
      "epoch: 27: 5969it [14:11,  7.01it/s]\n",
      "epoch: 28: 5969it [14:12,  7.00it/s]\n",
      "epoch: 29: 5969it [14:13,  6.99it/s]\n",
      "epoch: 30: 5969it [14:11,  7.01it/s]\n",
      "epoch: 31: 5969it [14:13,  6.99it/s]\n",
      "epoch: 32: 5969it [14:11,  7.01it/s]\n",
      "epoch: 33: 5969it [14:13,  7.00it/s]\n",
      "epoch: 34: 5969it [14:11,  7.01it/s]\n",
      "epoch: 35: 5969it [14:12,  7.00it/s]\n",
      "epoch: 36: 5969it [14:11,  7.01it/s]\n",
      "epoch: 37: 5969it [14:12,  7.00it/s]\n",
      "epoch: 38: 5969it [14:12,  7.00it/s]\n",
      "epoch: 39: 5969it [14:13,  7.00it/s]\n",
      "epoch: 40: 5969it [14:13,  7.00it/s]\n",
      "epoch: 41: 5969it [14:12,  7.00it/s]\n",
      "epoch: 42: 5969it [14:12,  7.00it/s]\n",
      "epoch: 43: 5969it [14:11,  7.01it/s]\n",
      "epoch: 44: 5969it [14:12,  7.00it/s]\n",
      "epoch: 45: 5969it [14:11,  7.01it/s]\n",
      "epoch: 46: 5969it [14:14,  6.99it/s]\n",
      "epoch: 47: 5969it [14:15,  6.98it/s]\n",
      "epoch: 48: 5969it [14:14,  6.99it/s]\n",
      "epoch: 49: 5969it [14:16,  6.97it/s]\n",
      "epoch: 50: 5969it [14:12,  7.00it/s]\n",
      "epoch: 51: 5969it [14:15,  6.98it/s]\n",
      "epoch: 52: 5969it [14:14,  6.98it/s]\n",
      "epoch: 53: 5969it [14:13,  6.99it/s]\n",
      "epoch: 54: 5969it [14:13,  7.00it/s]\n",
      "epoch: 55: 5969it [14:13,  6.99it/s]\n",
      "epoch: 56: 5969it [14:14,  6.99it/s]\n",
      "epoch: 57: 5969it [14:15,  6.98it/s]\n",
      "epoch: 58: 5969it [14:17,  6.96it/s]\n",
      "epoch: 59: 5969it [14:14,  6.99it/s]\n",
      "epoch: 60: 5969it [14:15,  6.97it/s]\n",
      "epoch: 61: 5969it [14:14,  6.99it/s]\n",
      "epoch: 62: 5969it [14:16,  6.97it/s]\n",
      "epoch: 63: 5969it [14:14,  6.98it/s]\n",
      "epoch: 64: 5969it [14:15,  6.98it/s]\n",
      "epoch: 65: 5969it [14:13,  6.99it/s]\n",
      "epoch: 66: 5969it [14:14,  6.98it/s]\n",
      "epoch: 67: 5969it [14:13,  6.99it/s]\n",
      "epoch: 68: 5969it [14:14,  6.99it/s]\n",
      "epoch: 69: 5969it [14:12,  7.00it/s]\n",
      "epoch: 70: 5969it [14:09,  7.02it/s]\n",
      "epoch: 71: 5969it [14:11,  7.01it/s]\n",
      "epoch: 72: 5969it [14:10,  7.02it/s]\n",
      "epoch: 73: 5969it [14:11,  7.01it/s]\n",
      "epoch: 74: 5969it [14:10,  7.02it/s]\n",
      "epoch: 75: 5969it [14:10,  7.01it/s]\n",
      "epoch: 76: 5969it [14:09,  7.02it/s]\n",
      "epoch: 77: 5969it [14:09,  7.02it/s]\n",
      "epoch: 78: 5969it [14:10,  7.02it/s]\n",
      "epoch: 79: 5969it [14:08,  7.03it/s]\n",
      "epoch: 80: 5969it [14:10,  7.02it/s]\n",
      "epoch: 81: 5969it [14:08,  7.03it/s]\n",
      "epoch: 82: 5969it [14:09,  7.02it/s]\n",
      "epoch: 83: 5969it [14:10,  7.02it/s]\n",
      "epoch: 84: 5969it [14:10,  7.02it/s]\n",
      "epoch: 85: 5969it [14:10,  7.02it/s]\n",
      "epoch: 86: 5969it [14:10,  7.02it/s]\n",
      "epoch: 87: 5969it [14:10,  7.02it/s]\n",
      "epoch: 88: 5969it [14:09,  7.03it/s]\n",
      "epoch: 89: 5969it [14:10,  7.01it/s]\n",
      "epoch: 90: 5969it [14:10,  7.02it/s]\n",
      "epoch: 91: 5969it [14:11,  7.01it/s]\n",
      "epoch: 92: 5969it [14:11,  7.01it/s]\n",
      "epoch: 93: 5969it [14:11,  7.01it/s]\n",
      "epoch: 94: 5969it [14:11,  7.01it/s]\n",
      "epoch: 95: 5969it [14:10,  7.02it/s]\n",
      "epoch: 96: 5969it [14:10,  7.01it/s]\n",
      "epoch: 97: 5969it [14:10,  7.02it/s]\n",
      "epoch: 98: 5969it [14:12,  7.01it/s]\n",
      "epoch: 99: 5969it [14:10,  7.02it/s]\n",
      "epoch: 100: 5013it [11:55,  7.03it/s]"
     ]
    }
   ],
   "source": [
    "train(args, data_provider=frag20_eMol9_QM_dataset, use_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
