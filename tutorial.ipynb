{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction to Explore Chemical Space with 3D Geometry and Deep Learning\n",
    "\n",
    "This is a tutorial on how to train a simplified PhysNet (sPhysNet) on Frag20 dataset described in this [paper]($PLACEHOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the code and data\n",
    "\n",
    "First you should download the code for data preprocessing (/dataProviders) and model training(/PhysDime-Seq). You can do it by:\n",
    "\n",
    "\n",
    "` $ git clone --recurse-submodules -j8 https://github.com/SongXia-NYU/sPhysNet.git`\n",
    "\n",
    "You need to setup the environment variable:\n",
    "\n",
    "` $ export PYTHONPATH=./dataProviders/:$PYTHONPATH `\n",
    "\n",
    "` $ export PYTHONPATH=./PhysDime-Seq/:$PYTHONPATH `\n",
    "\n",
    "before you launch this notebook: \n",
    "\n",
    "` $ jupyter notebook `\n",
    "\n",
    "This tutorial file is supposed to be in the /sPhysNet folder, which is the same level as /dataProviders and /PhysDime-Seq\n",
    "\n",
    "Download Frag20 data from our website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-09 15:52:03--  https://www.nyu.edu/projects/yzhang/IMA/Datasets/Frag20.tar.bz2\n",
      "Resolving www.nyu.edu (www.nyu.edu)... 216.165.47.12, 2607:f600:1002:6113::100\n",
      "Connecting to www.nyu.edu (www.nyu.edu)|216.165.47.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 369836924 (353M) [application/x-bzip2]\n",
      "Saving to: 'Frag20.tar.bz2'\n",
      "\n",
      "Frag20.tar.bz2      100%[===================>] 352.70M  32.9MB/s    in 13s     \n",
      "\n",
      "2021-03-09 15:52:16 (28.2 MB/s) - 'Frag20.tar.bz2' saved [369836924/369836924]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download from our website: https://www.nyu.edu/projects/yzhang/IMA\n",
    "! wget https://www.nyu.edu/projects/yzhang/IMA/Datasets/Frag20.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-09 16:36:05--  https://www.nyu.edu/projects/yzhang/IMA/Datasets/eMol9_MMFF.tar.bz2\n",
      "Resolving www.nyu.edu (www.nyu.edu)... 216.165.47.12, 2607:f600:1002:6113::100\n",
      "Connecting to www.nyu.edu (www.nyu.edu)|216.165.47.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51168717 (49M) [application/x-bzip2]\n",
      "Saving to: 'eMol9_MMFF.tar.bz2'\n",
      "\n",
      "eMol9_MMFF.tar.bz2  100%[===================>]  48.80M  31.5MB/s    in 1.5s    \n",
      "\n",
      "2021-03-09 16:36:06 (31.5 MB/s) - 'eMol9_MMFF.tar.bz2' saved [51168717/51168717]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://www.nyu.edu/projects/yzhang/IMA/Datasets/eMol9_MMFF.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to extract the *.tar.bz2 file; Check [this](https://www.geeksforgeeks.org/tar-command-linux-examples/) if you are not sure. After extraction you will get more than a million (1,000,000) small files. Due to the restriction on my HPC, I put them into a singularity file. Contact your administrator if you are not sure wether there is a file number limit.\n",
    "\n",
    "You will need to change the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change me to your extracted location\n",
    "frag20_data_root = \"/ext3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change me to your extracted location \n",
    "eMol9_data_root = \"/scratch/sx801/data/eMol9/eMol9_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_frag20_data(root):\n",
    "    for n_heavy in range(9, 21):\n",
    "        csv_file = osp.join(root, \"Frag20_{}_target.csv\".format(n_heavy))\n",
    "        pt_file = osp.join(root, \"Frag20_{}_extra_target.pt\".format(n_heavy))\n",
    "        sdf_folder = osp.join(root, \"Frag20_{}_data\".format(n_heavy))\n",
    "        for f in [csv_file, pt_file, sdf_folder]:\n",
    "            if not osp.exists(f):\n",
    "                raise ValueError(\"file/folder: {} doesn't exist! Is your root correct?\".format(f))\n",
    "    print(\"Frag20 data status: Normal\")\n",
    "    \n",
    "def check_eMol9_data(root):\n",
    "    csv_file = osp.join(root, \"eMol9_target.csv\")\n",
    "    pt_file = osp.join(root, \"eMol9_extra_target.pt\")\n",
    "    sdf_folder = osp.join(root, \"eMol9_data\")\n",
    "    for f in [csv_file, pt_file, sdf_folder]:\n",
    "        if not osp.exists(f):\n",
    "            raise ValueError(\"file/folder: {} doesn't exist! Is your root correct?\".format(f))\n",
    "    print(\"eMol9 data status: Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frag20 data status: Normal\n"
     ]
    }
   ],
   "source": [
    "check_frag20_data(frag20_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eMol9 data status: Normal\n"
     ]
    }
   ],
   "source": [
    "check_eMol9_data(eMol9_data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the downloaded data, all geometries and targets are in different format. There we need to preprocess them into a single `torch_geometric.data.InMemoryDataset` format. I have written a function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataProviders.GaussUtils.GaussInfo import sdf_to_pt\n",
    "dst_dir = \"dataProviders/data/processed\"\n",
    "os.makedirs(dst_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing extract geometry, targets and calculate `edge_index` as well. The whole process takes several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing heavy: 9: 100%|██████████| 158535/158535 [22:09<00:00, 119.24it/s]\n",
      "processing heavy: 10: 100%|██████████| 143180/143180 [29:36<00:00, 80.61it/s] \n",
      "processing heavy: 11: 100%|██████████| 17269/17269 [03:28<00:00, 82.85it/s] \n",
      "processing heavy: 12: 100%|██████████| 21502/21502 [05:00<00:00, 71.51it/s] \n",
      "processing heavy: 13: 100%|██████████| 25793/25793 [06:51<00:00, 62.61it/s] \n",
      "processing heavy: 14: 100%|██████████| 30331/30331 [09:01<00:00, 56.03it/s] \n",
      "processing heavy: 15: 100%|██████████| 31719/31719 [10:20<00:00, 51.13it/s]\n",
      "processing heavy: 16: 100%|██████████| 35584/35584 [12:41<00:00, 46.72it/s]\n",
      "processing heavy: 17: 100%|██████████| 36201/36201 [14:15<00:00, 42.31it/s]\n",
      "processing heavy: 18: 100%|██████████| 32501/32501 [14:04<00:00, 38.49it/s]\n",
      "processing heavy: 19: 100%|██████████| 23474/23474 [11:19<00:00, 34.55it/s]\n",
      "processing heavy: 20: 100%|██████████| 10207/10207 [05:48<00:00, 29.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# ------------- Frag20 Data preprocess, QM------------- #\n",
    "\n",
    "for n_heavy in range(9, 21):\n",
    "    sdf_to_pt(n_heavy=n_heavy, src_root=frag20_data_root, dst_root=dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing heavy: 9: 100%|██████████| 158535/158535 [24:02<00:00, 109.93it/s]\n",
      "processing heavy: 10: 100%|██████████| 143180/143180 [31:32<00:00, 75.66it/s] \n",
      "processing heavy: 11: 100%|██████████| 17269/17269 [03:32<00:00, 81.12it/s] \n",
      "processing heavy: 12: 100%|██████████| 21502/21502 [05:18<00:00, 67.53it/s] \n",
      "processing heavy: 13: 100%|██████████| 25793/25793 [07:14<00:00, 59.37it/s] \n",
      "processing heavy: 14: 100%|██████████| 30331/30331 [09:33<00:00, 52.86it/s] \n",
      "processing heavy: 15: 100%|██████████| 31719/31719 [10:52<00:00, 48.59it/s]\n",
      "processing heavy: 16: 100%|██████████| 35584/35584 [13:18<00:00, 44.56it/s]\n",
      "processing heavy: 17: 100%|██████████| 36201/36201 [14:54<00:00, 40.49it/s]\n",
      "processing heavy: 18: 100%|██████████| 32501/32501 [14:41<00:00, 36.87it/s]\n",
      "processing heavy: 19: 100%|██████████| 23474/23474 [11:47<00:00, 33.18it/s]\n",
      "processing heavy: 20: 100%|██████████| 10207/10207 [06:03<00:00, 28.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# ------------- Frag20 Data preprocess, MMFF------------- #\n",
    "\n",
    "for n_heavy in range(9, 21):\n",
    "    sdf_to_pt(n_heavy=n_heavy, src_root=frag20_data_root, dst_root=dst_dir, geometry=\"mmff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R',\n",
       " 'Z',\n",
       " 'Q',\n",
       " 'D',\n",
       " 'F',\n",
       " 'E',\n",
       " 'N',\n",
       " 'BN_edge_index',\n",
       " 'L_edge_index',\n",
       " 'num_L_edge',\n",
       " 'num_BN_edge']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag20_20_raw = torch.load(\"dataProviders/raw/frag20_20_raw.pt\")\n",
    "frag20_20_raw[0].keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the data was processed into PyTorch geometric InMemoryDataset format. \n",
    "\n",
    "The keys are:\n",
    "\n",
    "- \"R\": Coordinate of each atom, will be processed into distance matrix on the fly\n",
    "- \"Z\": Atomic number of each atom\n",
    "- \"Q\": Total charge of each molecule\n",
    "- \"D\": Dipole of each molecule\n",
    "- \"F\": Force of each molecule, set to 0.0 since all molecules are QM optimized\n",
    "- \"E\": Atomic energy of each molecule\n",
    "- \"N\": Total number of atoms in each molecule\n",
    "- \"BN_edge_index\": atom pairs within defined cutoff (10.0 A)\n",
    "- \"L_edge_index\": atom pairs with distance larger than cutoff\n",
    "- \"num_BN_edge\"/\"num_L_edge\": number of pairs in each molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also you need to do the same procedure to preprocess eMol9 Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from dataProviders.GaussUtils.GaussInfo import sdf_to_pt_eMol9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88234/88234 [15:54<00:00, 92.45it/s] \n"
     ]
    }
   ],
   "source": [
    "# -----------eMol9 QM------------ #\n",
    "sdf_to_pt_eMol9(src_root=eMol9_data_root, dst_root=dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88234/88234 [23:59<00:00, 61.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# ----------eMol9 MMFF----------- #\n",
    "sdf_to_pt_eMol9(src_root=eMol9_data_root, dst_root=dst_dir, geometry=\"mmff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataProviders/data/processed/eMol9_raw.pt\r\n",
      "dataProviders/data/processed/eMol9_raw_mmff.pt\r\n"
     ]
    }
   ],
   "source": [
    "! ls dataProviders/data/processed/eMol9*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "frag20_9_raw.pt: 100%|██████████| 158535/158535 [00:25<00:00, 6105.57it/s]\n",
      "frag20_10_raw.pt: 100%|██████████| 143180/143180 [00:23<00:00, 6061.26it/s]\n",
      "frag20_11_raw.pt: 100%|██████████| 17269/17269 [00:02<00:00, 7031.08it/s]\n",
      "frag20_12_raw.pt: 100%|██████████| 21502/21502 [00:03<00:00, 7070.70it/s]\n",
      "frag20_13_raw.pt: 100%|██████████| 25793/25793 [00:03<00:00, 7028.68it/s]\n",
      "frag20_14_raw.pt: 100%|██████████| 30331/30331 [00:06<00:00, 5044.81it/s]\n",
      "frag20_15_raw.pt: 100%|██████████| 31719/31719 [00:04<00:00, 6991.87it/s]\n",
      "frag20_16_raw.pt: 100%|██████████| 35584/35584 [00:07<00:00, 5025.57it/s]\n",
      "frag20_17_raw.pt: 100%|██████████| 36201/36201 [00:05<00:00, 7054.65it/s]\n",
      "frag20_18_raw.pt: 100%|██████████| 32501/32501 [00:04<00:00, 7038.79it/s]\n",
      "frag20_19_raw.pt: 100%|██████████| 23474/23474 [00:03<00:00, 7073.40it/s]\n",
      "frag20_20_raw.pt: 100%|██████████| 10207/10207 [00:01<00:00, 7070.00it/s]\n",
      "eMol9_raw.pt: 100%|██████████| 88234/88234 [00:15<00:00, 5865.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving... it is recommended to have 32GB memory\n"
     ]
    }
   ],
   "source": [
    "# ----------- Concat datasets, QM ----------------- #\n",
    "\n",
    "# recommened memory: 32GB\n",
    "from DataPrepareUtils import concat_im_datasets\n",
    "data_root = \"./dataProviders/data\"\n",
    "datasets = [\"frag20_{}_raw.pt\".format(i) for i in range(9, 21)]\n",
    "datasets.append(\"eMol9_raw.pt\")\n",
    "concat_im_datasets(root=data_root, datasets=datasets, out_name=\"Frag20_eMol9_QM.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frag20_9_mmff_raw.pt: 100%|██████████| 158535/158535 [00:36<00:00, 4335.67it/s]\n",
      "frag20_10_mmff_raw.pt: 100%|██████████| 143180/143180 [00:33<00:00, 4276.44it/s]\n",
      "frag20_11_mmff_raw.pt: 100%|██████████| 17269/17269 [00:03<00:00, 4633.92it/s]\n",
      "frag20_12_mmff_raw.pt: 100%|██████████| 21502/21502 [00:04<00:00, 4607.68it/s]\n",
      "frag20_13_mmff_raw.pt: 100%|██████████| 25793/25793 [00:06<00:00, 3706.22it/s]\n",
      "frag20_14_mmff_raw.pt: 100%|██████████| 30331/30331 [00:06<00:00, 4621.71it/s]\n",
      "frag20_15_mmff_raw.pt: 100%|██████████| 31719/31719 [00:06<00:00, 4632.25it/s]\n",
      "frag20_16_mmff_raw.pt: 100%|██████████| 35584/35584 [00:09<00:00, 3726.44it/s]\n",
      "frag20_17_mmff_raw.pt: 100%|██████████| 36201/36201 [00:07<00:00, 4631.08it/s]\n",
      "frag20_18_mmff_raw.pt: 100%|██████████| 32501/32501 [00:07<00:00, 4635.32it/s]\n",
      "frag20_19_mmff_raw.pt: 100%|██████████| 23474/23474 [00:07<00:00, 3265.35it/s]\n",
      "frag20_20_mmff_raw.pt: 100%|██████████| 10207/10207 [00:02<00:00, 4633.60it/s]\n",
      "eMol9_raw_mmff.pt: 100%|██████████| 88234/88234 [00:19<00:00, 4632.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving... it is recommended to have 32GB memory\n"
     ]
    }
   ],
   "source": [
    "# ----------- Concat datasets, MMFF ----------------- #\n",
    "\n",
    "# recommened memory: 32GB\n",
    "from DataPrepareUtils import concat_im_datasets\n",
    "data_root = \"./dataProviders/data\"\n",
    "datasets = [\"frag20_{}_mmff_raw.pt\".format(i) for i in range(9, 21)]\n",
    "datasets.append(\"eMol9_raw_mmff.pt\")\n",
    "concat_im_datasets(root=data_root, datasets=datasets, out_name=\"Frag20_eMol9_MMFF.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now we have prepared frag20 and eMol9 dataset with QM geometry. We are ready for training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method I: command line\n",
    "\n",
    "You can directly train it in the command line:\n",
    "\n",
    "Make sure you are in the `PhysDime-Seq` folder\n",
    "\n",
    "```cmd\n",
    "$ export PYTHONPATH=../dataProviders:PYTHONPATH\n",
    "$ python train.py --config_name config-sPhysNet-Frag20-eMol9-QM.txt\n",
    "```\n",
    "\n",
    "After training a QM model, you can fine-tune a MMFF model by this:\n",
    "\n",
    "```\n",
    "$ python train.py --config_name config-sPhysNet-Frag20-eMol9-MMFF.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method II: in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sx801/scripts/sPhysNet\n",
      "/scratch/sx801/scripts/sPhysNet/PhysDime-Seq\n",
      "/scratch/sx801/scripts/sPhysNet/PhysDime-Seq\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "%cd PhysDime-Seq\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DummyIMDataset import DummyIMDataset\n",
    "frag20_eMol9_QM_dataset = DummyIMDataset(root=\"../dataProviders/data\", dataset_name=\"Frag20_eMol9_QM.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654530"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frag20_eMol9_QM_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the same result as the paper, we will load the same train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = torch.load(\"../dataProviders/frag20_eMol9_split.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([583261,  19821, 213143,  ...,  90419, 482983, 121258])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train-valid split is randomly generated on the fly\n",
    "train_perm = torch.randperm(len(split[\"train_index\"]))\n",
    "train_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag20_eMol9_QM_dataset.train_index = split[\"train_index\"][train_perm[:-1000]]\n",
    "frag20_eMol9_QM_dataset.val_index = split[\"train_index\"][train_perm[-1000:]]\n",
    "frag20_eMol9_QM_dataset.test_index = split[\"test_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--debug_mode=False\r\n",
      "--modules=P-noOut P-noOut P C\r\n",
      "--bonding_type=BN BN BN BN\r\n",
      "--activations=ssp ssp ssp\r\n",
      "--expansion_fn=(P_BN,P-noOut_BN):gaussian_64_10.0 C_BN:coulomb_10.0\r\n",
      "--n_feature=160\r\n",
      "--n_dime_before_residual=1\r\n",
      "--n_dime_after_residual=2\r\n",
      "--n_output_dense=3\r\n",
      "--n_phys_atomic_res=1\r\n",
      "--n_phys_interaction_res=1\r\n",
      "--n_phys_output_res=1\r\n",
      "--n_bi_linear=8\r\n",
      "--num_epochs=1000\r\n",
      "--warm_up_steps=0\r\n",
      "--data_provider=dummy[dataset_name=Frag20_eMol9_QM.pt,split=frag20_eMol9_split.pt]\r\n",
      "--test_interval=-1\r\n",
      "--learning_rate=0.001\r\n",
      "--ema_decay=0.999\r\n",
      "--l2lambda=0.0\r\n",
      "--nh_lambda=0.01\r\n",
      "--restrain_non_bond_pred=True\r\n",
      "--decay_steps=620000\r\n",
      "--decay_rate=0.1\r\n",
      "--batch_size=100\r\n",
      "--valid_batch_size=32\r\n",
      "--force_weight=0\r\n",
      "--charge_weight=1\r\n",
      "--dipole_weight=1\r\n",
      "--use_trained_model=False\r\n",
      "--max_norm=1000.0\r\n",
      "--log_file_name=training.log\r\n",
      "--normalize=True\r\n",
      "--shared_normalize_param=True\r\n",
      "--edge_version=cutoff\r\n",
      "--cutoff=10.0\r\n",
      "--boundary_factor=100.\r\n",
      "--remove_atom_ids=-1\r\n",
      "--folder_prefix=exp-sPhysNet-QM\r\n",
      "--comment=original PhysNet, coulomb correction\r\n",
      "--coulomb_charge_correct=True\r\n"
     ]
    }
   ],
   "source": [
    "# Use this config file to train a sPhysNet in the paper\n",
    "! cat config-sPhysNet-Frag20-eMol9-QM.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_functions import add_parser_arguments\n",
    "config_name = \"config-sPhysNet-Frag20-eMol9-QM.txt\"\n",
    "# set up parser and arguments\n",
    "parser = argparse.ArgumentParser(fromfile_prefix_chars='@')\n",
    "parser = add_parser_arguments(parser)\n",
    "\n",
    "args, unknown = parser.parse_known_args([\"@\" + config_name])\n",
    "args.config_name = config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(BN_edge_index=[2, 272], D=[1, 3], E=[1], F=[1, 3], L_edge_index=[2, 0], N=[1], Q=[1], R=[17, 3], Z=[17], num_BN_edge=[1], num_L_edge=[1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag20_eMol9_QM_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7892096)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag20_eMol9_QM_dataset.data.num_L_edge.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING ATOM -1 FROM DATASET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0: 5969it [15:36,  6.37it/s]\n",
      "epoch: 1: 5969it [14:12,  7.00it/s]\n",
      "epoch: 2: 5969it [14:13,  7.00it/s]\n",
      "epoch: 3: 5969it [14:12,  7.00it/s]\n",
      "epoch: 4: 5969it [14:13,  6.99it/s]\n",
      "epoch: 5: 5969it [14:04,  7.07it/s]\n",
      "epoch: 6: 5969it [14:10,  7.02it/s]\n",
      "epoch: 7: 5969it [14:10,  7.01it/s]\n",
      "epoch: 8: 5969it [14:11,  7.01it/s]\n",
      "epoch: 9: 5969it [14:12,  7.00it/s]\n",
      "epoch: 10: 5969it [14:10,  7.02it/s]\n",
      "epoch: 11: 5969it [14:12,  7.00it/s]\n",
      "epoch: 12: 5969it [14:11,  7.01it/s]\n",
      "epoch: 13: 5969it [14:11,  7.01it/s]\n",
      "epoch: 14: 5969it [14:11,  7.01it/s]\n",
      "epoch: 15: 5969it [14:11,  7.01it/s]\n",
      "epoch: 16: 5969it [14:14,  6.99it/s]\n",
      "epoch: 17: 5969it [14:12,  7.00it/s]\n",
      "epoch: 18: 5969it [14:12,  7.00it/s]\n",
      "epoch: 19: 5969it [14:12,  7.00it/s]\n",
      "epoch: 20: 5969it [14:13,  6.99it/s]\n",
      "epoch: 21: 5969it [14:11,  7.01it/s]\n",
      "epoch: 22: 5969it [14:13,  7.00it/s]\n",
      "epoch: 23: 5969it [14:11,  7.01it/s]\n",
      "epoch: 24: 5969it [14:12,  7.01it/s]\n",
      "epoch: 25: 5969it [14:11,  7.01it/s]\n",
      "epoch: 26: 5969it [14:12,  7.00it/s]\n",
      "epoch: 27: 5969it [14:11,  7.01it/s]\n",
      "epoch: 28: 5969it [14:12,  7.00it/s]\n",
      "epoch: 29: 5969it [14:13,  6.99it/s]\n",
      "epoch: 30: 5969it [14:11,  7.01it/s]\n",
      "epoch: 31: 5969it [14:13,  6.99it/s]\n",
      "epoch: 32: 5969it [14:11,  7.01it/s]\n",
      "epoch: 33: 5969it [14:13,  7.00it/s]\n",
      "epoch: 34: 5969it [14:11,  7.01it/s]\n",
      "epoch: 35: 5969it [14:12,  7.00it/s]\n",
      "epoch: 36: 5969it [14:11,  7.01it/s]\n",
      "epoch: 37: 5969it [14:12,  7.00it/s]\n",
      "epoch: 38: 5969it [14:12,  7.00it/s]\n",
      "epoch: 39: 5969it [14:13,  7.00it/s]\n",
      "epoch: 40: 5969it [14:13,  7.00it/s]\n",
      "epoch: 41: 5969it [14:12,  7.00it/s]\n",
      "epoch: 42: 5969it [14:12,  7.00it/s]\n",
      "epoch: 43: 5969it [14:11,  7.01it/s]\n",
      "epoch: 44: 5969it [14:12,  7.00it/s]\n",
      "epoch: 45: 5969it [14:11,  7.01it/s]\n",
      "epoch: 46: 5969it [14:14,  6.99it/s]\n",
      "epoch: 47: 5969it [14:15,  6.98it/s]\n",
      "epoch: 48: 5969it [14:14,  6.99it/s]\n",
      "epoch: 49: 5969it [14:16,  6.97it/s]\n",
      "epoch: 50: 5969it [14:12,  7.00it/s]\n",
      "epoch: 51: 5969it [14:15,  6.98it/s]\n",
      "epoch: 52: 5969it [14:14,  6.98it/s]\n",
      "epoch: 53: 5969it [14:13,  6.99it/s]\n",
      "epoch: 54: 5969it [14:13,  7.00it/s]\n",
      "epoch: 55: 5969it [14:13,  6.99it/s]\n",
      "epoch: 56: 5969it [14:14,  6.99it/s]\n",
      "epoch: 57: 5969it [14:15,  6.98it/s]\n",
      "epoch: 58: 5969it [14:17,  6.96it/s]\n",
      "epoch: 59: 5969it [14:14,  6.99it/s]\n",
      "epoch: 60: 5969it [14:15,  6.97it/s]\n",
      "epoch: 61: 5969it [14:14,  6.99it/s]\n",
      "epoch: 62: 5969it [14:16,  6.97it/s]\n",
      "epoch: 63: 5969it [14:14,  6.98it/s]\n",
      "epoch: 64: 5969it [14:15,  6.98it/s]\n",
      "epoch: 65: 5969it [14:13,  6.99it/s]\n",
      "epoch: 66: 5969it [14:14,  6.98it/s]\n",
      "epoch: 67: 5969it [14:13,  6.99it/s]\n",
      "epoch: 68: 5969it [14:14,  6.99it/s]\n",
      "epoch: 69: 5969it [14:12,  7.00it/s]\n",
      "epoch: 70: 5969it [14:09,  7.02it/s]\n",
      "epoch: 71: 5969it [14:11,  7.01it/s]\n",
      "epoch: 72: 5969it [14:10,  7.02it/s]\n",
      "epoch: 73: 5969it [14:11,  7.01it/s]\n",
      "epoch: 74: 5969it [14:10,  7.02it/s]\n",
      "epoch: 75: 5969it [14:10,  7.01it/s]\n",
      "epoch: 76: 5969it [14:09,  7.02it/s]\n",
      "epoch: 77: 5969it [14:09,  7.02it/s]\n",
      "epoch: 78: 5969it [14:10,  7.02it/s]\n",
      "epoch: 79: 5969it [14:08,  7.03it/s]\n",
      "epoch: 80: 5969it [14:10,  7.02it/s]\n",
      "epoch: 81: 5969it [14:08,  7.03it/s]\n",
      "epoch: 82: 5969it [14:09,  7.02it/s]\n",
      "epoch: 83: 5969it [14:10,  7.02it/s]\n",
      "epoch: 84: 5969it [14:10,  7.02it/s]\n",
      "epoch: 85: 5969it [14:10,  7.02it/s]\n",
      "epoch: 86: 5969it [14:10,  7.02it/s]\n",
      "epoch: 87: 5969it [14:10,  7.02it/s]\n",
      "epoch: 88: 5969it [14:09,  7.03it/s]\n",
      "epoch: 89: 5969it [14:10,  7.01it/s]\n",
      "epoch: 90: 5969it [14:10,  7.02it/s]\n",
      "epoch: 91: 5969it [14:11,  7.01it/s]\n",
      "epoch: 92: 5969it [14:11,  7.01it/s]\n",
      "epoch: 93: 5969it [14:11,  7.01it/s]\n",
      "epoch: 94: 5969it [14:11,  7.01it/s]\n",
      "epoch: 95: 5969it [14:10,  7.02it/s]\n",
      "epoch: 96: 5969it [14:10,  7.01it/s]\n",
      "epoch: 97: 5969it [14:10,  7.02it/s]\n",
      "epoch: 98: 5969it [14:12,  7.01it/s]\n",
      "epoch: 99: 5969it [14:10,  7.02it/s]\n",
      "epoch: 100: 5013it [11:55,  7.03it/s]"
     ]
    }
   ],
   "source": [
    "train(args, data_provider=frag20_eMol9_QM_dataset, use_tqdm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMFF geometry fine-tuning can be achieved by replacing `Frag20_eMol9_QM.pt` with `Frag20_eMol9_MMFF.pt` and `config-sPhysNet-Frag20-eMol9-QM.txt` with `config-sPhysNet-Frag20-eMol9-MMFF.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
